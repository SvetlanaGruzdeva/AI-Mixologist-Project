{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv('./clean_data/clean_data.csv')\n",
    "df_loaded.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation of dataset for ML training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strDrink</th>\n",
       "      <th>strCategory</th>\n",
       "      <th>strGlass</th>\n",
       "      <th>strIngredients</th>\n",
       "      <th>Alc_type</th>\n",
       "      <th>Basic_taste</th>\n",
       "      <th>strInstructions</th>\n",
       "      <th>strMeasures</th>\n",
       "      <th>Value</th>\n",
       "      <th>MeasureName</th>\n",
       "      <th>Value_numeric</th>\n",
       "      <th>Value_ml</th>\n",
       "      <th>Value_gr</th>\n",
       "      <th>Garnish_amount</th>\n",
       "      <th>Garnish_type</th>\n",
       "      <th>MeasureName_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'57 Chevy with a White License Plate</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>Highball glass</td>\n",
       "      <td>Creme De Cacao White</td>\n",
       "      <td>Creamy Liqueur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Fill a rocks glass with ice 2.add white cre...</td>\n",
       "      <td>1 oz white</td>\n",
       "      <td>1</td>\n",
       "      <td>oz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-900-FUK-MEUP</td>\n",
       "      <td>Shot</td>\n",
       "      <td>Old-fashioned glass</td>\n",
       "      <td>Absolut Kurant</td>\n",
       "      <td>Vodka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shake ingredients in a mixing tin filled with ...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110 in the shade</td>\n",
       "      <td>Beer</td>\n",
       "      <td>Beer Glass</td>\n",
       "      <td>Lager</td>\n",
       "      <td>Beer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drop shooter in glass. Fill with beer</td>\n",
       "      <td>16 oz</td>\n",
       "      <td>16</td>\n",
       "      <td>oz</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151 Florida Bushwacker</td>\n",
       "      <td>Milk / Float / Shake</td>\n",
       "      <td>Beer mug</td>\n",
       "      <td>Malibu Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Combine all ingredients. Blend until smooth. G...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155 Belmont</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>White wine glass</td>\n",
       "      <td>Dark Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blend with ice. Serve in a wine glass. Garnish...</td>\n",
       "      <td>1 shot</td>\n",
       "      <td>1</td>\n",
       "      <td>shot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               strDrink           strCategory  \\\n",
       "0  '57 Chevy with a White License Plate              Cocktail   \n",
       "1                        1-900-FUK-MEUP                  Shot   \n",
       "2                      110 in the shade                  Beer   \n",
       "3                151 Florida Bushwacker  Milk / Float / Shake   \n",
       "4                           155 Belmont              Cocktail   \n",
       "\n",
       "              strGlass        strIngredients        Alc_type Basic_taste  \\\n",
       "0       Highball glass  Creme De Cacao White  Creamy Liqueur         NaN   \n",
       "1  Old-fashioned glass        Absolut Kurant           Vodka         NaN   \n",
       "2           Beer Glass                 Lager            Beer         NaN   \n",
       "3             Beer mug            Malibu Rum             Rum         NaN   \n",
       "4     White wine glass              Dark Rum             Rum         NaN   \n",
       "\n",
       "                                     strInstructions strMeasures Value  \\\n",
       "0  1. Fill a rocks glass with ice 2.add white cre...  1 oz white     1   \n",
       "1  Shake ingredients in a mixing tin filled with ...      1/2 oz   1/2   \n",
       "2              Drop shooter in glass. Fill with beer       16 oz    16   \n",
       "3  Combine all ingredients. Blend until smooth. G...      1/2 oz   1/2   \n",
       "4  Blend with ice. Serve in a wine glass. Garnish...      1 shot     1   \n",
       "\n",
       "  MeasureName  Value_numeric  Value_ml  Value_gr Garnish_amount Garnish_type  \\\n",
       "0          oz            1.0      30.0       NaN            NaN          NaN   \n",
       "1          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "2          oz           16.0     480.0       NaN            NaN          NaN   \n",
       "3          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "4        shot            1.0      25.0       NaN            NaN          NaN   \n",
       "\n",
       "  MeasureName_copy  \n",
       "0            white  \n",
       "1               oz  \n",
       "2               oz  \n",
       "3               oz  \n",
       "4             shot  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_loaded.drop('MeasureName_copy', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[(df['Value_ml'].isnull()) & (df['Value_gr'].isnull()) & (df['Garnish_amount'].isnull())].index,\n",
    "                                                                                                           axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ml', 'gr', 'garnish'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fill new column with correct measure names\n",
    "\n",
    "df['Measure'] = np.nan\n",
    "df['Measure'] = df['Measure'].astype('object')\n",
    "df['Measure'] = np.where((~df['Value_ml'].isnull()), 'ml', 'gr')\n",
    "df['Measure'] = np.where(~df['Garnish_amount'].isnull(), 'garnish', df['Measure'])\n",
    "df['Measure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strDrink</th>\n",
       "      <th>strCategory</th>\n",
       "      <th>strGlass</th>\n",
       "      <th>strIngredients</th>\n",
       "      <th>Alc_type</th>\n",
       "      <th>Basic_taste</th>\n",
       "      <th>strInstructions</th>\n",
       "      <th>strMeasures</th>\n",
       "      <th>Value</th>\n",
       "      <th>MeasureName</th>\n",
       "      <th>Value_numeric</th>\n",
       "      <th>Value_ml</th>\n",
       "      <th>Value_gr</th>\n",
       "      <th>Garnish_amount</th>\n",
       "      <th>Garnish_type</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'57 Chevy with a White License Plate</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>Highball glass</td>\n",
       "      <td>Creme De Cacao White</td>\n",
       "      <td>Creamy Liqueur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Fill a rocks glass with ice 2.add white cre...</td>\n",
       "      <td>1 oz white</td>\n",
       "      <td>1</td>\n",
       "      <td>oz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-900-FUK-MEUP</td>\n",
       "      <td>Shot</td>\n",
       "      <td>Old-fashioned glass</td>\n",
       "      <td>Absolut Kurant</td>\n",
       "      <td>Vodka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shake ingredients in a mixing tin filled with ...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110 in the shade</td>\n",
       "      <td>Beer</td>\n",
       "      <td>Beer Glass</td>\n",
       "      <td>Lager</td>\n",
       "      <td>Beer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drop shooter in glass. Fill with beer</td>\n",
       "      <td>16 oz</td>\n",
       "      <td>16</td>\n",
       "      <td>oz</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151 Florida Bushwacker</td>\n",
       "      <td>Milk / Float / Shake</td>\n",
       "      <td>Beer mug</td>\n",
       "      <td>Malibu Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Combine all ingredients. Blend until smooth. G...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155 Belmont</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>White wine glass</td>\n",
       "      <td>Dark Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blend with ice. Serve in a wine glass. Garnish...</td>\n",
       "      <td>1 shot</td>\n",
       "      <td>1</td>\n",
       "      <td>shot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               strDrink           strCategory  \\\n",
       "0  '57 Chevy with a White License Plate              Cocktail   \n",
       "1                        1-900-FUK-MEUP                  Shot   \n",
       "2                      110 in the shade                  Beer   \n",
       "3                151 Florida Bushwacker  Milk / Float / Shake   \n",
       "4                           155 Belmont              Cocktail   \n",
       "\n",
       "              strGlass        strIngredients        Alc_type Basic_taste  \\\n",
       "0       Highball glass  Creme De Cacao White  Creamy Liqueur         NaN   \n",
       "1  Old-fashioned glass        Absolut Kurant           Vodka         NaN   \n",
       "2           Beer Glass                 Lager            Beer         NaN   \n",
       "3             Beer mug            Malibu Rum             Rum         NaN   \n",
       "4     White wine glass              Dark Rum             Rum         NaN   \n",
       "\n",
       "                                     strInstructions strMeasures Value  \\\n",
       "0  1. Fill a rocks glass with ice 2.add white cre...  1 oz white     1   \n",
       "1  Shake ingredients in a mixing tin filled with ...      1/2 oz   1/2   \n",
       "2              Drop shooter in glass. Fill with beer       16 oz    16   \n",
       "3  Combine all ingredients. Blend until smooth. G...      1/2 oz   1/2   \n",
       "4  Blend with ice. Serve in a wine glass. Garnish...      1 shot     1   \n",
       "\n",
       "  MeasureName  Value_numeric  Value_ml  Value_gr Garnish_amount Garnish_type  \\\n",
       "0          oz            1.0      30.0       NaN            NaN          NaN   \n",
       "1          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "2          oz           16.0     480.0       NaN            NaN          NaN   \n",
       "3          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "4        shot            1.0      25.0       NaN            NaN          NaN   \n",
       "\n",
       "  Measure Volume  \n",
       "0      ml     30  \n",
       "1      ml     15  \n",
       "2      ml    480  \n",
       "3      ml     15  \n",
       "4      ml     25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fill new column with correct amounts of each ingredient\n",
    "\n",
    "df['Volume'] = np.nan\n",
    "df['Volume'] = df['Volume'].astype('object')\n",
    "df['Volume'] = np.where(df['Measure'] == 'ml', df['Value_ml'], df['Value_gr'])\n",
    "df['Volume'] = np.where(df['Measure'] == 'garnish', (df['Garnish_amount']+' '+df['Garnish_type']), df['Volume'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ingredient, volume and measure in one sentence\n",
    "\n",
    "def combine(line, ingr_col1, ingr_col2=None):\n",
    "    if ingr_col2:\n",
    "        lst1 = [line[ingr_col1], line[ingr_col2], line['Volume'], line['Measure']]\n",
    "    else:\n",
    "        lst1 = [line[ingr_col1], line['Volume'], line['Measure']]\n",
    "    lst2 = [str(i) for i in lst1 if str(i) != 'nan']\n",
    "    return ' '.join(lst2)\n",
    "\n",
    "    \n",
    "# combine(df.iloc[1], 'Alc_type')      # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One column - alcohol type and basic taste\n",
    "# Another column - ingredients as they are\n",
    "# Third column - alcohol type and non-alcoholic ingredient\n",
    "\n",
    "df['Sentence_type'] = df.apply(lambda x: combine(x, 'Alc_type', 'Basic_taste'), axis=1)\n",
    "df['Sentence_ingr'] = df.apply(lambda x: combine(x, 'strIngredients'), axis=1)\n",
    "df['Sentence_type_ingr'] = np.where(df['Alc_type'].isnull(),\n",
    "                                    df.apply(lambda x: combine(x, 'strIngredients'), axis=1),\n",
    "                                    df.apply(lambda x: combine(x, 'Alc_type'), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strDrink</th>\n",
       "      <th>strCategory</th>\n",
       "      <th>strGlass</th>\n",
       "      <th>strIngredients</th>\n",
       "      <th>Alc_type</th>\n",
       "      <th>Basic_taste</th>\n",
       "      <th>strInstructions</th>\n",
       "      <th>strMeasures</th>\n",
       "      <th>Value</th>\n",
       "      <th>MeasureName</th>\n",
       "      <th>Value_numeric</th>\n",
       "      <th>Value_ml</th>\n",
       "      <th>Value_gr</th>\n",
       "      <th>Garnish_amount</th>\n",
       "      <th>Garnish_type</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sentence_type</th>\n",
       "      <th>Sentence_ingr</th>\n",
       "      <th>Sentence_type_ingr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'57 Chevy with a White License Plate</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>Highball glass</td>\n",
       "      <td>Creme De Cacao White</td>\n",
       "      <td>Creamy Liqueur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Fill a rocks glass with ice 2.add white cre...</td>\n",
       "      <td>1 oz white</td>\n",
       "      <td>1</td>\n",
       "      <td>oz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>30</td>\n",
       "      <td>Creamy Liqueur 30.0 ml</td>\n",
       "      <td>Creme De Cacao White 30.0 ml</td>\n",
       "      <td>Creamy Liqueur 30.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-900-FUK-MEUP</td>\n",
       "      <td>Shot</td>\n",
       "      <td>Old-fashioned glass</td>\n",
       "      <td>Absolut Kurant</td>\n",
       "      <td>Vodka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shake ingredients in a mixing tin filled with ...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>15</td>\n",
       "      <td>Vodka 15.0 ml</td>\n",
       "      <td>Absolut Kurant 15.0 ml</td>\n",
       "      <td>Vodka 15.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110 in the shade</td>\n",
       "      <td>Beer</td>\n",
       "      <td>Beer Glass</td>\n",
       "      <td>Lager</td>\n",
       "      <td>Beer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drop shooter in glass. Fill with beer</td>\n",
       "      <td>16 oz</td>\n",
       "      <td>16</td>\n",
       "      <td>oz</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>480</td>\n",
       "      <td>Beer 480.0 ml</td>\n",
       "      <td>Lager 480.0 ml</td>\n",
       "      <td>Beer 480.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151 Florida Bushwacker</td>\n",
       "      <td>Milk / Float / Shake</td>\n",
       "      <td>Beer mug</td>\n",
       "      <td>Malibu Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Combine all ingredients. Blend until smooth. G...</td>\n",
       "      <td>1/2 oz</td>\n",
       "      <td>1/2</td>\n",
       "      <td>oz</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>15</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>Malibu Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155 Belmont</td>\n",
       "      <td>Cocktail</td>\n",
       "      <td>White wine glass</td>\n",
       "      <td>Dark Rum</td>\n",
       "      <td>Rum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blend with ice. Serve in a wine glass. Garnish...</td>\n",
       "      <td>1 shot</td>\n",
       "      <td>1</td>\n",
       "      <td>shot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ml</td>\n",
       "      <td>25</td>\n",
       "      <td>Rum 25.0 ml</td>\n",
       "      <td>Dark Rum 25.0 ml</td>\n",
       "      <td>Rum 25.0 ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               strDrink           strCategory  \\\n",
       "0  '57 Chevy with a White License Plate              Cocktail   \n",
       "1                        1-900-FUK-MEUP                  Shot   \n",
       "2                      110 in the shade                  Beer   \n",
       "3                151 Florida Bushwacker  Milk / Float / Shake   \n",
       "4                           155 Belmont              Cocktail   \n",
       "\n",
       "              strGlass        strIngredients        Alc_type Basic_taste  \\\n",
       "0       Highball glass  Creme De Cacao White  Creamy Liqueur         NaN   \n",
       "1  Old-fashioned glass        Absolut Kurant           Vodka         NaN   \n",
       "2           Beer Glass                 Lager            Beer         NaN   \n",
       "3             Beer mug            Malibu Rum             Rum         NaN   \n",
       "4     White wine glass              Dark Rum             Rum         NaN   \n",
       "\n",
       "                                     strInstructions strMeasures Value  \\\n",
       "0  1. Fill a rocks glass with ice 2.add white cre...  1 oz white     1   \n",
       "1  Shake ingredients in a mixing tin filled with ...      1/2 oz   1/2   \n",
       "2              Drop shooter in glass. Fill with beer       16 oz    16   \n",
       "3  Combine all ingredients. Blend until smooth. G...      1/2 oz   1/2   \n",
       "4  Blend with ice. Serve in a wine glass. Garnish...      1 shot     1   \n",
       "\n",
       "  MeasureName  Value_numeric  Value_ml  Value_gr Garnish_amount Garnish_type  \\\n",
       "0          oz            1.0      30.0       NaN            NaN          NaN   \n",
       "1          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "2          oz           16.0     480.0       NaN            NaN          NaN   \n",
       "3          oz            0.5      15.0       NaN            NaN          NaN   \n",
       "4        shot            1.0      25.0       NaN            NaN          NaN   \n",
       "\n",
       "  Measure Volume           Sentence_type                 Sentence_ingr  \\\n",
       "0      ml     30  Creamy Liqueur 30.0 ml  Creme De Cacao White 30.0 ml   \n",
       "1      ml     15           Vodka 15.0 ml        Absolut Kurant 15.0 ml   \n",
       "2      ml    480           Beer 480.0 ml                Lager 480.0 ml   \n",
       "3      ml     15             Rum 15.0 ml            Malibu Rum 15.0 ml   \n",
       "4      ml     25             Rum 25.0 ml              Dark Rum 25.0 ml   \n",
       "\n",
       "       Sentence_type_ingr  \n",
       "0  Creamy Liqueur 30.0 ml  \n",
       "1           Vodka 15.0 ml  \n",
       "2           Beer 480.0 ml  \n",
       "3             Rum 15.0 ml  \n",
       "4             Rum 25.0 ml  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strDrink</th>\n",
       "      <th>Sentence_ingr_1</th>\n",
       "      <th>Sentence_type_1</th>\n",
       "      <th>Sentence_type_ingr_1</th>\n",
       "      <th>Sentence_ingr_2</th>\n",
       "      <th>Sentence_type_2</th>\n",
       "      <th>Sentence_type_ingr_2</th>\n",
       "      <th>Sentence_ingr_3</th>\n",
       "      <th>Sentence_type_3</th>\n",
       "      <th>Sentence_type_ingr_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Sentence_type_ingr_8</th>\n",
       "      <th>Sentence_ingr_9</th>\n",
       "      <th>Sentence_type_9</th>\n",
       "      <th>Sentence_type_ingr_9</th>\n",
       "      <th>Sentence_ingr_10</th>\n",
       "      <th>Sentence_type_10</th>\n",
       "      <th>Sentence_type_ingr_10</th>\n",
       "      <th>Sentence_ingr_11</th>\n",
       "      <th>Sentence_type_11</th>\n",
       "      <th>Sentence_type_ingr_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'57 Chevy with a White License Plate</td>\n",
       "      <td>Creme De Cacao White 30.0 ml</td>\n",
       "      <td>Creamy Liqueur 30.0 ml</td>\n",
       "      <td>Creamy Liqueur 30.0 ml</td>\n",
       "      <td>Vodka 30.0 ml</td>\n",
       "      <td>Vodka 30.0 ml</td>\n",
       "      <td>Vodka 30.0 ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-900-FUK-MEUP</td>\n",
       "      <td>Absolut Kurant 15.0 ml</td>\n",
       "      <td>Vodka 15.0 ml</td>\n",
       "      <td>Vodka 15.0 ml</td>\n",
       "      <td>Grand Marnier 7.5 ml</td>\n",
       "      <td>Triple Sec 7.5 ml</td>\n",
       "      <td>Triple Sec 7.5 ml</td>\n",
       "      <td>Chambord Raspberry Liqueur 7.5 ml</td>\n",
       "      <td>Sweet Liqueur 7.5 ml</td>\n",
       "      <td>Sweet Liqueur 7.5 ml</td>\n",
       "      <td>...</td>\n",
       "      <td>Pineapple Juice 7.5 ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110 in the shade</td>\n",
       "      <td>Lager 480.0 ml</td>\n",
       "      <td>Beer 480.0 ml</td>\n",
       "      <td>Beer 480.0 ml</td>\n",
       "      <td>Tequila 45.0 ml</td>\n",
       "      <td>Tequila 45.0 ml</td>\n",
       "      <td>Tequila 45.0 ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151 Florida Bushwacker</td>\n",
       "      <td>Malibu Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>Light Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>151 Proof Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>Rum 15.0 ml</td>\n",
       "      <td>...</td>\n",
       "      <td>Vanilla Ice-Cream 128.0 gr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155 Belmont</td>\n",
       "      <td>Dark Rum 25.0 ml</td>\n",
       "      <td>Rum 25.0 ml</td>\n",
       "      <td>Rum 25.0 ml</td>\n",
       "      <td>Light Rum 50.0 ml</td>\n",
       "      <td>Rum 50.0 ml</td>\n",
       "      <td>Rum 50.0 ml</td>\n",
       "      <td>Vodka 25.0 ml</td>\n",
       "      <td>Vodka 25.0 ml</td>\n",
       "      <td>Vodka 25.0 ml</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               strDrink               Sentence_ingr_1  \\\n",
       "0  '57 Chevy with a White License Plate  Creme De Cacao White 30.0 ml   \n",
       "1                        1-900-FUK-MEUP        Absolut Kurant 15.0 ml   \n",
       "2                      110 in the shade                Lager 480.0 ml   \n",
       "3                151 Florida Bushwacker            Malibu Rum 15.0 ml   \n",
       "4                           155 Belmont              Dark Rum 25.0 ml   \n",
       "\n",
       "          Sentence_type_1    Sentence_type_ingr_1       Sentence_ingr_2  \\\n",
       "0  Creamy Liqueur 30.0 ml  Creamy Liqueur 30.0 ml         Vodka 30.0 ml   \n",
       "1           Vodka 15.0 ml           Vodka 15.0 ml  Grand Marnier 7.5 ml   \n",
       "2           Beer 480.0 ml           Beer 480.0 ml       Tequila 45.0 ml   \n",
       "3             Rum 15.0 ml             Rum 15.0 ml     Light Rum 15.0 ml   \n",
       "4             Rum 25.0 ml             Rum 25.0 ml     Light Rum 50.0 ml   \n",
       "\n",
       "     Sentence_type_2 Sentence_type_ingr_2                    Sentence_ingr_3  \\\n",
       "0      Vodka 30.0 ml        Vodka 30.0 ml                                NaN   \n",
       "1  Triple Sec 7.5 ml    Triple Sec 7.5 ml  Chambord Raspberry Liqueur 7.5 ml   \n",
       "2    Tequila 45.0 ml      Tequila 45.0 ml                                NaN   \n",
       "3        Rum 15.0 ml          Rum 15.0 ml              151 Proof Rum 15.0 ml   \n",
       "4        Rum 50.0 ml          Rum 50.0 ml                      Vodka 25.0 ml   \n",
       "\n",
       "        Sentence_type_3  Sentence_type_ingr_3  ...  \\\n",
       "0                   NaN                   NaN  ...   \n",
       "1  Sweet Liqueur 7.5 ml  Sweet Liqueur 7.5 ml  ...   \n",
       "2                   NaN                   NaN  ...   \n",
       "3           Rum 15.0 ml           Rum 15.0 ml  ...   \n",
       "4         Vodka 25.0 ml         Vodka 25.0 ml  ...   \n",
       "\n",
       "         Sentence_type_ingr_8 Sentence_ingr_9 Sentence_type_9  \\\n",
       "0                         NaN             NaN             NaN   \n",
       "1      Pineapple Juice 7.5 ml             NaN             NaN   \n",
       "2                         NaN             NaN             NaN   \n",
       "3  Vanilla Ice-Cream 128.0 gr             NaN             NaN   \n",
       "4                         NaN             NaN             NaN   \n",
       "\n",
       "  Sentence_type_ingr_9 Sentence_ingr_10 Sentence_type_10  \\\n",
       "0                  NaN              NaN              NaN   \n",
       "1                  NaN              NaN              NaN   \n",
       "2                  NaN              NaN              NaN   \n",
       "3                  NaN              NaN              NaN   \n",
       "4                  NaN              NaN              NaN   \n",
       "\n",
       "  Sentence_type_ingr_10 Sentence_ingr_11 Sentence_type_11  \\\n",
       "0                   NaN              NaN              NaN   \n",
       "1                   NaN              NaN              NaN   \n",
       "2                   NaN              NaN              NaN   \n",
       "3                   NaN              NaN              NaN   \n",
       "4                   NaN              NaN              NaN   \n",
       "\n",
       "  Sentence_type_ingr_11  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reallocate ingredients as columns so each cocktail takes only one row\n",
    "\n",
    "df_cut = df[['strDrink', 'Sentence_type', 'Sentence_ingr', 'Sentence_type_ingr']]\n",
    "s =  df_cut.groupby('strDrink').cumcount().add(1)\n",
    "df_cut = (df_cut.set_index(['strDrink',s]).unstack().sort_index(axis=1, level=1))\n",
    "df_cut.columns = ['{}_{}'.format(a, b) for a,b in df_cut.columns]\n",
    "\n",
    "df_cut = df_cut.reset_index()\n",
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(line, col):\n",
    "    lst1 = [line[col+'_'+str(i)] for i in range(1, 12)]\n",
    "    lst2 = [str(i) for i in lst1 if str(i) != 'nan']\n",
    "    return ' '.join(lst2)\n",
    "\n",
    "        \n",
    "# combine(df_cut.iloc[1], 'Sentence_ingr')      # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Sentence_ingr', 'Sentence_type', 'Sentence_type_ingr']\n",
    "for i in cols:\n",
    "    df_cut[i] = df_cut.apply(lambda x: combine(x, i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strDrink</th>\n",
       "      <th>Sentence_ingr</th>\n",
       "      <th>Sentence_type</th>\n",
       "      <th>Sentence_type_ingr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'57 Chevy with a White License Plate</td>\n",
       "      <td>Creme De Cacao White 30.0 ml Vodka 30.0 ml</td>\n",
       "      <td>Creamy Liqueur 30.0 ml Vodka 30.0 ml</td>\n",
       "      <td>Creamy Liqueur 30.0 ml Vodka 30.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-900-FUK-MEUP</td>\n",
       "      <td>Absolut Kurant 15.0 ml Grand Marnier 7.5 ml Ch...</td>\n",
       "      <td>Vodka 15.0 ml Triple Sec 7.5 ml Sweet Liqueur ...</td>\n",
       "      <td>Vodka 15.0 ml Triple Sec 7.5 ml Sweet Liqueur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110 in the shade</td>\n",
       "      <td>Lager 480.0 ml Tequila 45.0 ml</td>\n",
       "      <td>Beer 480.0 ml Tequila 45.0 ml</td>\n",
       "      <td>Beer 480.0 ml Tequila 45.0 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151 Florida Bushwacker</td>\n",
       "      <td>Malibu Rum 15.0 ml Light Rum 15.0 ml 151 Proof...</td>\n",
       "      <td>Rum 15.0 ml Rum 15.0 ml Rum 15.0 ml Creamy Liq...</td>\n",
       "      <td>Rum 15.0 ml Rum 15.0 ml Rum 15.0 ml Creamy Liq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155 Belmont</td>\n",
       "      <td>Dark Rum 25.0 ml Light Rum 50.0 ml Vodka 25.0 ...</td>\n",
       "      <td>Rum 25.0 ml Rum 50.0 ml Vodka 25.0 ml sweet 25...</td>\n",
       "      <td>Rum 25.0 ml Rum 50.0 ml Vodka 25.0 ml Orange J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               strDrink  \\\n",
       "0  '57 Chevy with a White License Plate   \n",
       "1                        1-900-FUK-MEUP   \n",
       "2                      110 in the shade   \n",
       "3                151 Florida Bushwacker   \n",
       "4                           155 Belmont   \n",
       "\n",
       "                                       Sentence_ingr  \\\n",
       "0         Creme De Cacao White 30.0 ml Vodka 30.0 ml   \n",
       "1  Absolut Kurant 15.0 ml Grand Marnier 7.5 ml Ch...   \n",
       "2                     Lager 480.0 ml Tequila 45.0 ml   \n",
       "3  Malibu Rum 15.0 ml Light Rum 15.0 ml 151 Proof...   \n",
       "4  Dark Rum 25.0 ml Light Rum 50.0 ml Vodka 25.0 ...   \n",
       "\n",
       "                                       Sentence_type  \\\n",
       "0               Creamy Liqueur 30.0 ml Vodka 30.0 ml   \n",
       "1  Vodka 15.0 ml Triple Sec 7.5 ml Sweet Liqueur ...   \n",
       "2                      Beer 480.0 ml Tequila 45.0 ml   \n",
       "3  Rum 15.0 ml Rum 15.0 ml Rum 15.0 ml Creamy Liq...   \n",
       "4  Rum 25.0 ml Rum 50.0 ml Vodka 25.0 ml sweet 25...   \n",
       "\n",
       "                                  Sentence_type_ingr  \n",
       "0               Creamy Liqueur 30.0 ml Vodka 30.0 ml  \n",
       "1  Vodka 15.0 ml Triple Sec 7.5 ml Sweet Liqueur ...  \n",
       "2                      Beer 480.0 ml Tequila 45.0 ml  \n",
       "3  Rum 15.0 ml Rum 15.0 ml Rum 15.0 ml Creamy Liq...  \n",
       "4  Rum 25.0 ml Rum 50.0 ml Vodka 25.0 ml Orange J...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cut = df_cut[['strDrink', 'Sentence_ingr', 'Sentence_type', 'Sentence_type_ingr']]\n",
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Creme De Cacao White 30.0 ml Vodka 30.0 ml',\n",
       " 'Absolut Kurant 15.0 ml Grand Marnier 7.5 ml Chambord Raspberry Liqueur 7.5 ml Midori Melon Liqueur 7.5 ml Malibu Rum 7.5 ml Amaretto 7.5 ml Cranberry Juice 15.0 ml Pineapple Juice 7.5 ml',\n",
       " 'Lager 480.0 ml Tequila 45.0 ml',\n",
       " 'Malibu Rum 15.0 ml Light Rum 15.0 ml 151 Proof Rum 15.0 ml Dark Creme De Cacao 30.0 ml Cointreau 30.0 ml Milk 90.0 ml Coconut Liqueur 30.0 ml Vanilla Ice-Cream 128.0 gr',\n",
       " 'Dark Rum 25.0 ml Light Rum 50.0 ml Vodka 25.0 ml Orange Juice 25.0 ml']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the column we want to use for training into list of strings\n",
    "\n",
    "text = df_cut['Sentence_ingr'].tolist()\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - remove all measures\n",
    "\n",
    "# text = df_cut['Sentence_ingr'].apply(lambda x: re.sub('gr', '', re.sub('ml', '', re.sub(r'\\d', '', x))))\n",
    "# text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39, 40, 82, 35, 2, 1, 12, 2, 1],\n",
       " [68,\n",
       "  196,\n",
       "  3,\n",
       "  1,\n",
       "  100,\n",
       "  101,\n",
       "  71,\n",
       "  1,\n",
       "  116,\n",
       "  91,\n",
       "  24,\n",
       "  71,\n",
       "  1,\n",
       "  107,\n",
       "  102,\n",
       "  24,\n",
       "  71,\n",
       "  1,\n",
       "  108,\n",
       "  10,\n",
       "  71,\n",
       "  1,\n",
       "  30,\n",
       "  71,\n",
       "  1,\n",
       "  54,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  50,\n",
       "  4,\n",
       "  71,\n",
       "  1]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Tokenizer object\n",
    "tokenizer = Tokenizer(num_words=None,      # Define how many most common words to keep. If none, all will be kept\n",
    "                      filters='',          # Includes punctuation by default but we need to keep dots and we don't have anything\n",
    "#                       filters='.#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                                           # to clean\n",
    "                      lower=False,         # We'd like to keep uppercase words\n",
    "                      split=' ')           # Words in strings are split by whitespace\n",
    "\n",
    "# Train the tokenizer to the texts\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "# Convert list of strings into list of lists of integers\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'ml',\n",
       " 2: '30.0',\n",
       " 3: '15.0',\n",
       " 4: 'Juice',\n",
       " 5: 'gr',\n",
       " 6: 'garnish',\n",
       " 7: '60.0',\n",
       " 8: '45.0',\n",
       " 9: 'Lemon',\n",
       " 10: 'Rum',\n",
       " 11: '1',\n",
       " 12: 'Vodka',\n",
       " 13: 'Gin',\n",
       " 14: 'Orange',\n",
       " 15: 'Sugar',\n",
       " 16: '22.5',\n",
       " 17: 'Cream',\n",
       " 18: 'Light',\n",
       " 19: '4.0',\n",
       " 20: '25.0',\n",
       " 21: 'Lime',\n",
       " 22: 'Brandy',\n",
       " 23: '1.0',\n",
       " 24: 'Liqueur',\n",
       " 25: 'Vermouth',\n",
       " 26: 'Cherry',\n",
       " 27: '10.0',\n",
       " 28: 'Triple',\n",
       " 29: 'Sec',\n",
       " 30: 'Amaretto',\n",
       " 31: '2.0',\n",
       " 32: '90.0',\n",
       " 33: 'berry',\n",
       " 34: 'Bitters',\n",
       " 35: 'White',\n",
       " 36: 'Sweet',\n",
       " 37: '120.0',\n",
       " 38: 'Grenadine',\n",
       " 39: 'Creme',\n",
       " 40: 'De',\n",
       " 41: 'Peel',\n",
       " 42: 'slice',\n",
       " 43: 'Water',\n",
       " 44: 'Irish',\n",
       " 45: 'Powdered',\n",
       " 46: 'Tequila',\n",
       " 47: 'Kahlua',\n",
       " 48: 'twist',\n",
       " 49: 'Egg',\n",
       " 50: 'Pineapple',\n",
       " 51: 'Dry',\n",
       " 52: 'Soda',\n",
       " 53: 'Maraschino',\n",
       " 54: 'Cranberry',\n",
       " 55: '6.0',\n",
       " 56: '0',\n",
       " 57: 'top',\n",
       " 58: 'up',\n",
       " 59: \"Bailey'S\",\n",
       " 60: 'Schnapps',\n",
       " 61: 'Dark',\n",
       " 62: 'Sour',\n",
       " 63: '150.0',\n",
       " 64: '14.0',\n",
       " 65: 'Milk',\n",
       " 66: '20.0',\n",
       " 67: 'Syrup',\n",
       " 68: 'Absolut',\n",
       " 69: 'Peach',\n",
       " 70: 'Coffee',\n",
       " 71: '7.5',\n",
       " 72: '50.0',\n",
       " 73: '8.0',\n",
       " 74: 'Whiskey',\n",
       " 75: 'Bourbon',\n",
       " 76: 'Wine',\n",
       " 77: '75.0',\n",
       " 78: 'Ginger',\n",
       " 79: '40.0',\n",
       " 80: 'Scotch',\n",
       " 81: 'Superfine',\n",
       " 82: 'Cacao',\n",
       " 83: 'Vanilla',\n",
       " 84: '128.0',\n",
       " 85: 'And',\n",
       " 86: 'Curacao',\n",
       " 87: 'Nutmeg',\n",
       " 88: '0.5',\n",
       " 89: 'Red',\n",
       " 90: '5.0',\n",
       " 91: 'Raspberry',\n",
       " 92: '151',\n",
       " 93: 'Proof',\n",
       " 94: '12.5',\n",
       " 95: 'grated',\n",
       " 96: 'Apple',\n",
       " 97: 'Blue',\n",
       " 98: 'Club',\n",
       " 99: '750.0',\n",
       " 100: 'Grand',\n",
       " 101: 'Marnier',\n",
       " 102: 'Melon',\n",
       " 103: 'Ice-Cream',\n",
       " 104: '37.5',\n",
       " 105: 'Apricot',\n",
       " 106: '360.0',\n",
       " 107: 'Midori',\n",
       " 108: 'Malibu',\n",
       " 109: 'Beer',\n",
       " 110: 'Ale',\n",
       " 111: 'Salt',\n",
       " 112: 'Blended',\n",
       " 113: '180.0',\n",
       " 114: '236.5',\n",
       " 115: 'Sambuca',\n",
       " 116: 'Chambord',\n",
       " 117: 'Coca-Cola',\n",
       " 118: 'Citron',\n",
       " 119: 'Southern',\n",
       " 120: 'Comfort',\n",
       " 121: 'Menthe',\n",
       " 122: 'Chocolate',\n",
       " 123: 'Champagne',\n",
       " 124: 'Lemonade',\n",
       " 125: '2.5',\n",
       " 126: 'Benedictine',\n",
       " 127: '330.0',\n",
       " 128: 'Galliano',\n",
       " 129: 'Sauce',\n",
       " 130: 'Coconut',\n",
       " 131: 'Mint',\n",
       " 132: 'Mix',\n",
       " 133: 'Whipped',\n",
       " 134: '60',\n",
       " 135: 'Green',\n",
       " 136: 'Lager',\n",
       " 137: 'Cointreau',\n",
       " 138: 'Jägermeister',\n",
       " 139: 'Jack',\n",
       " 140: 'Strawberry',\n",
       " 141: 'Hot',\n",
       " 142: 'Cognac',\n",
       " 143: '3.0',\n",
       " 144: '946.0',\n",
       " 145: '240.0',\n",
       " 146: 'Cider',\n",
       " 147: '64.0',\n",
       " 148: 'Tea',\n",
       " 149: 'Frozen',\n",
       " 150: '125.0',\n",
       " 151: '32.0',\n",
       " 152: '270.0',\n",
       " 153: 'Goldschlager',\n",
       " 154: 'Daniels',\n",
       " 155: 'wedge',\n",
       " 156: 'Grapefruit',\n",
       " 157: 'Angostura',\n",
       " 158: 'Sprite',\n",
       " 159: 'Cassis',\n",
       " 160: 'Sherry',\n",
       " 161: 'Sloe',\n",
       " 162: 'Tabasco',\n",
       " 163: '0.36',\n",
       " 164: 'Port',\n",
       " 165: '100.0',\n",
       " 166: 'Olive',\n",
       " 167: '474.0',\n",
       " 168: 'Wild',\n",
       " 169: 'Turkey',\n",
       " 170: '7-Up',\n",
       " 171: 'Frangelico',\n",
       " 172: 'Strawberries',\n",
       " 173: 'Tonic',\n",
       " 174: 'leaf(ves)',\n",
       " 175: 'Heavy',\n",
       " 176: 'Fruit',\n",
       " 177: 'Campari',\n",
       " 178: 'whole',\n",
       " 179: 'Cinnamon',\n",
       " 180: 'Grape',\n",
       " 181: 'Jamaican',\n",
       " 182: 'Crown',\n",
       " 183: 'Royal',\n",
       " 184: 'Banana',\n",
       " 185: 'Everclear',\n",
       " 186: 'Kool-Aid',\n",
       " 187: 'around',\n",
       " 188: 'the',\n",
       " 189: 'rim',\n",
       " 190: '1/2',\n",
       " 191: 'Extract',\n",
       " 192: '11.25',\n",
       " 193: 'Lemon-Lime',\n",
       " 194: 'Or',\n",
       " 195: '105.0',\n",
       " 196: 'Kurant',\n",
       " 197: 'Banane',\n",
       " 198: '44.0',\n",
       " 199: '6.25',\n",
       " 200: 'Fresh',\n",
       " 201: 'Chartreuse',\n",
       " 202: 'Blackberry',\n",
       " 203: 'Cloves',\n",
       " 204: '3',\n",
       " 205: 'Mountain',\n",
       " 206: 'Dew',\n",
       " 207: 'Of',\n",
       " 208: '473.0',\n",
       " 209: '8.333333333333332',\n",
       " 210: '3785.0',\n",
       " 211: 'Guinness',\n",
       " 212: 'Stout',\n",
       " 213: 'Root',\n",
       " 214: 'Surge',\n",
       " 215: '175.0',\n",
       " 216: 'Godiva',\n",
       " 217: 'Butterscotch',\n",
       " 218: 'Tomato',\n",
       " 219: '711.0',\n",
       " 220: 'Corona',\n",
       " 221: 'Bacardi',\n",
       " 222: 'Limon',\n",
       " 223: 'Cachaca',\n",
       " 224: 'Yolk',\n",
       " 225: 'Spiced',\n",
       " 226: '42.0',\n",
       " 227: '1000.0',\n",
       " 228: 'Anis',\n",
       " 229: '12.0',\n",
       " 230: 'Jim',\n",
       " 231: 'Beam',\n",
       " 232: 'Añejo',\n",
       " 233: 'Applejack',\n",
       " 234: '3.125',\n",
       " 235: '18.75',\n",
       " 236: 'Nectar',\n",
       " 237: 'Pisang',\n",
       " 238: 'Ambon',\n",
       " 239: '0.72',\n",
       " 240: 'Yellow',\n",
       " 241: '6',\n",
       " 242: '1892.5',\n",
       " 243: 'Iced',\n",
       " 244: 'Cordial',\n",
       " 245: 'Smirnoff',\n",
       " 246: '210.0',\n",
       " 247: 'Prosecco',\n",
       " 248: 'Tropical',\n",
       " 249: 'Tia',\n",
       " 250: 'Maria',\n",
       " 251: '2000.0',\n",
       " 252: 'Advocaat',\n",
       " 253: 'Grated',\n",
       " 254: 'Peachtree',\n",
       " 255: '300.0',\n",
       " 256: '28.0',\n",
       " 257: 'Damn',\n",
       " 258: '2',\n",
       " 259: 'Blackcurrant',\n",
       " 260: '70.0',\n",
       " 261: 'Punch',\n",
       " 262: 'Pisco',\n",
       " 263: 'Pepper',\n",
       " 264: 'Skimmed',\n",
       " 265: 'Agave',\n",
       " 266: '80.0',\n",
       " 267: 'Cold',\n",
       " 268: 'Schweppes',\n",
       " 269: 'Drambuie',\n",
       " 270: 'Orgeat',\n",
       " 271: 'Pepsi',\n",
       " 272: 'Cola',\n",
       " 273: '1750.0',\n",
       " 274: 'Rub',\n",
       " 275: '355.0',\n",
       " 276: 'Anisette',\n",
       " 277: 'Ouzo',\n",
       " 278: 'Zima',\n",
       " 279: '480.0',\n",
       " 280: 'Rumple',\n",
       " 281: 'Minze',\n",
       " 282: 'Johnnie',\n",
       " 283: 'Walker',\n",
       " 284: '200.0',\n",
       " 285: 'Kirschwasser',\n",
       " 286: '43.75',\n",
       " 287: '165.0',\n",
       " 288: 'Kummel',\n",
       " 289: '22.0',\n",
       " 290: '3784.0',\n",
       " 291: 'Brown',\n",
       " 292: 'Allspice',\n",
       " 293: 'Ground',\n",
       " 294: 'sticks',\n",
       " 295: '600.0',\n",
       " 296: '4000.0',\n",
       " 297: 'Candy',\n",
       " 298: 'jelly',\n",
       " 299: 'fish',\n",
       " 300: '(candy)',\n",
       " 301: 'Maui',\n",
       " 302: 'Gold',\n",
       " 303: 'Rye',\n",
       " 304: 'Passion',\n",
       " 305: '52.5',\n",
       " 306: \"Boone's\",\n",
       " 307: 'Hill',\n",
       " 308: 'Berry',\n",
       " 309: 'Celery',\n",
       " 310: 'Worcestershire',\n",
       " 311: 'Caramel',\n",
       " 312: 'Mini-Snickers',\n",
       " 313: 'Bars',\n",
       " 314: '450.0',\n",
       " 315: 'Label',\n",
       " 316: 'Erin',\n",
       " 317: 'Mure',\n",
       " 318: 'Muscatel',\n",
       " 319: 'Demerara',\n",
       " 320: 'Heering',\n",
       " 321: 'Brine',\n",
       " 322: 'Dubonnet',\n",
       " 323: 'Rouge',\n",
       " 324: 'St.',\n",
       " 325: 'Germain',\n",
       " 326: 'pinch',\n",
       " 327: 'Lavender',\n",
       " 328: 'sprigs',\n",
       " 329: 'Whipping',\n",
       " 330: 'Condensed',\n",
       " 331: '390.0',\n",
       " 332: '177.75',\n",
       " 333: 'Firewater',\n",
       " 334: 'Peppar',\n",
       " 335: 'Dr.',\n",
       " 336: '87.5',\n",
       " 337: 'Sarsaparilla',\n",
       " 338: '262.5',\n",
       " 339: '62.5',\n",
       " 340: 'Sirup',\n",
       " 341: 'Roses',\n",
       " 342: 'Carbonated',\n",
       " 343: '4',\n",
       " 344: 'Hard',\n",
       " 345: 'Whisky',\n",
       " 346: 'Very',\n",
       " 347: 'strip',\n",
       " 348: 'Aperol',\n",
       " 349: 'Tennessee',\n",
       " 350: 'Baileys',\n",
       " 351: '58.33333333333333',\n",
       " 352: 'Jello',\n",
       " 353: '88.0',\n",
       " 354: 'Grain',\n",
       " 355: 'Alcohol',\n",
       " 356: 'Apfelkorn',\n",
       " 357: 'Russchian',\n",
       " 358: 'Kiwi',\n",
       " 359: 'Bitter',\n",
       " 360: 'Turkish',\n",
       " 361: '237.0',\n",
       " 362: 'Tropicana',\n",
       " 363: '49.99999999999999',\n",
       " 364: 'Hazlenut',\n",
       " 365: 'Double',\n",
       " 366: 'Cocoa',\n",
       " 367: 'Powder',\n",
       " 368: 'Absinthe',\n",
       " 369: '12',\n",
       " 370: 'Sweetened',\n",
       " 371: 'Oreo',\n",
       " 372: 'Cookie',\n",
       " 373: 'Pink',\n",
       " 374: 'Black',\n",
       " 375: '250.0',\n",
       " 376: '1500.0',\n",
       " 377: '225.0',\n",
       " 378: 'Plain',\n",
       " 379: 'Ricard',\n",
       " 380: 'Peychaud',\n",
       " 381: '990.0',\n",
       " 382: '192.0',\n",
       " 383: 'Squash',\n",
       " 384: 'Cherries',\n",
       " 385: '1380.0',\n",
       " 386: '840.0',\n",
       " 387: 'Berries',\n",
       " 388: 'Aquavit',\n",
       " 389: 'Yukon',\n",
       " 390: 'Maple',\n",
       " 391: 'Lillet',\n",
       " 392: 'Blanc',\n",
       " 393: 'Unsweetened',\n",
       " 394: 'Half-And-Half',\n",
       " 395: 'Limeade',\n",
       " 396: '160.0'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The way to convert it back to words\n",
    "\n",
    "idx_word = tokenizer.index_word\n",
    "idx_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set features and labels. In our case features will be pair of words and a label will be the third word following defined pair. We will repeat this labeling with step 1 (i.e. every time second word becomes first word etc) for every sentence we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 10)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "training_length = 10\n",
    "\n",
    "# Iterate through the sequences of tokens:\n",
    "for seq in sequences:\n",
    "    \n",
    "    # Create a multiple training examples from each sequence\n",
    "    for i in range(training_length, len(seq)):\n",
    "        \n",
    "        # Extract the features and label\n",
    "        extract = seq[(i - training_length):(i + 1)]\n",
    "        \n",
    "        # Set the features and label\n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])\n",
    "        \n",
    "features = np.array(features)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform labels to one-hot encoded, this way neural network trains the most effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 397)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words in vocabulary\n",
    "num_words = len(idx_word) + 1\n",
    "\n",
    "# Empty array to hold labels\n",
    "label_array = np.zeros((len(features), num_words), dtype = np.int32)\n",
    "\n",
    "# One hot encode for labels\n",
    "for example_index, word_index in enumerate(labels):\n",
    "    label_array[example_index, word_index] = 1\n",
    "\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cranberry'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find word corresponding to encoding\n",
    "idx_word[np.argmax(label_array[100])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "            ModelCheckpoint('../models/model.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Embedding layer\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=num_words,\n",
    "              input_length = training_length,\n",
    "              output_dim=20,\n",
    "#               weights=[embedding_matrix],\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "\n",
    "# Masking layer for pre-trained embeddings\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "# Recurrent payer\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected payer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 5.2600 - accuracy: 0.1811WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 16ms/step - loss: 5.2316 - accuracy: 0.1821\n",
      "Epoch 2/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 4.2429 - accuracy: 0.1986WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 4.2438 - accuracy: 0.1997\n",
      "Epoch 3/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 4.0984 - accuracy: 0.2096WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 4.1189 - accuracy: 0.2038\n",
      "Epoch 4/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 4.0823 - accuracy: 0.2039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 4.0822 - accuracy: 0.2049\n",
      "Epoch 5/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 3.9931 - accuracy: 0.2066WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.9984 - accuracy: 0.2064\n",
      "Epoch 6/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 3.8578 - accuracy: 0.2112WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 3.8528 - accuracy: 0.2121\n",
      "Epoch 7/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 3.6795 - accuracy: 0.2365WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.6754 - accuracy: 0.2374\n",
      "Epoch 8/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 3.4787 - accuracy: 0.2581WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.4632 - accuracy: 0.2606\n",
      "Epoch 9/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 3.2812 - accuracy: 0.2818WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.2670 - accuracy: 0.2843\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.1095 - accuracy: 0.3194WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 3.1095 - accuracy: 0.3194\n",
      "Epoch 11/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.9867 - accuracy: 0.3210WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.9925 - accuracy: 0.3199\n",
      "Epoch 12/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 2.9062 - accuracy: 0.3497WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.8866 - accuracy: 0.3555\n",
      "Epoch 13/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.8145 - accuracy: 0.3575WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.8027 - accuracy: 0.3586\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.7369 - accuracy: 0.3684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.7369 - accuracy: 0.3684\n",
      "Epoch 15/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 2.6819 - accuracy: 0.3818WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.6783 - accuracy: 0.3808\n",
      "Epoch 16/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 2.6094 - accuracy: 0.4003WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.6057 - accuracy: 0.4004\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.5670 - accuracy: 0.4076WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.5670 - accuracy: 0.4076\n",
      "Epoch 18/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 2.4655 - accuracy: 0.4224WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.4705 - accuracy: 0.4221\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.4386 - accuracy: 0.4138WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 2.4386 - accuracy: 0.4138\n",
      "Epoch 20/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 2.3968 - accuracy: 0.4318WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.3947 - accuracy: 0.4324\n",
      "Epoch 21/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.3320 - accuracy: 0.4386WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.3283 - accuracy: 0.4376\n",
      "Epoch 22/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 2.2813 - accuracy: 0.4488WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.2857 - accuracy: 0.4499\n",
      "Epoch 23/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.2315 - accuracy: 0.47 - ETA: 0s - loss: 2.2452 - accuracy: 0.4682WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.2421 - accuracy: 0.4680\n",
      "Epoch 24/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.2081 - accuracy: 0.4624WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.1997 - accuracy: 0.4644\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.1434 - accuracy: 0.4825WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.1434 - accuracy: 0.4825\n",
      "Epoch 26/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 2.1355 - accuracy: 0.4666WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.1278 - accuracy: 0.4680\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/61 [============================>.] - ETA: 0s - loss: 2.0876 - accuracy: 0.4812WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 2.0869 - accuracy: 0.4804\n",
      "Epoch 28/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 2.0667 - accuracy: 0.4801WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.0654 - accuracy: 0.4825\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.0123 - accuracy: 0.4959WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 2.0123 - accuracy: 0.4959\n",
      "Epoch 30/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.9811 - accuracy: 0.5005WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.9883 - accuracy: 0.4995\n",
      "Epoch 31/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.9740 - accuracy: 0.5065WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.9689 - accuracy: 0.5077\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.9293 - accuracy: 0.5160WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.9293 - accuracy: 0.5160\n",
      "Epoch 33/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.9075 - accuracy: 0.5334WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.9125 - accuracy: 0.5315\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.9061 - accuracy: 0.5144WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.9061 - accuracy: 0.5144\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8257 - accuracy: 0.5351WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.8257 - accuracy: 0.5351\n",
      "Epoch 36/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.8168 - accuracy: 0.5271WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.8294 - accuracy: 0.5243\n",
      "Epoch 37/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.7957 - accuracy: 0.5370WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.7919 - accuracy: 0.5377\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7482 - accuracy: 0.5557 ETA: 0s - loss: 1.7535 - accuracy: WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.7482 - accuracy: 0.5557\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7536 - accuracy: 0.5475 ETA: 0s - loss: 1.7074 - WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.7536 - accuracy: 0.5475\n",
      "Epoch 40/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.7405 - accuracy: 0.5487WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.7376 - accuracy: 0.5501\n",
      "Epoch 41/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.7207 - accuracy: 0.5523WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.7258 - accuracy: 0.5531\n",
      "Epoch 42/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.6831 - accuracy: 0.5535WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.6831 - accuracy: 0.5562\n",
      "Epoch 43/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.6811 - accuracy: 0.5636WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.6897 - accuracy: 0.5609\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6550 - accuracy: 0.5686WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.6550 - accuracy: 0.5686\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.5599WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.6037 - accuracy: 0.5599\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6242 - accuracy: 0.5691WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.6242 - accuracy: 0.5691\n",
      "Epoch 47/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.5903 - accuracy: 0.5755WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.5923 - accuracy: 0.5753\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5789 - accuracy: 0.5779 ETA: 0s - loss: 1.5419 - accuraWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.5789 - accuracy: 0.5779\n",
      "Epoch 49/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.5603 - accuracy: 0.5768 ETA: 0s - loss: 1.5389 - accuracyWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.5553 - accuracy: 0.5769\n",
      "Epoch 50/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.5659 - accuracy: 0.5700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.5691 - accuracy: 0.5707\n",
      "Epoch 51/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.5442 - accuracy: 0.5839WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.5461 - accuracy: 0.5831\n",
      "Epoch 52/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.5262 - accuracy: 0.5854WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 1.5210 - accuracy: 0.5867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.4984 - accuracy: 0.5974WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 1.4976 - accuracy: 0.5975\n",
      "Epoch 54/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.4817 - accuracy: 0.5921WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4888 - accuracy: 0.5882\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.6068 ETA: 0s - loss: 1.5102 - accuraWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4639 - accuracy: 0.6068\n",
      "Epoch 56/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.4723 - accuracy: 0.5959WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4807 - accuracy: 0.5939\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4354 - accuracy: 0.6001WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4354 - accuracy: 0.6001\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4476 - accuracy: 0.5965WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4476 - accuracy: 0.5965\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.5918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4707 - accuracy: 0.5918\n",
      "Epoch 60/100\n",
      "57/61 [===========================>..] - ETA: 0s - loss: 1.4322 - accuracy: 0.5998WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.4306 - accuracy: 0.6006\n",
      "Epoch 61/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.3939 - accuracy: 0.6125WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3919 - accuracy: 0.6130\n",
      "Epoch 62/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.3926 - accuracy: 0.6175WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3927 - accuracy: 0.6166\n",
      "Epoch 63/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.3757 - accuracy: 0.6165WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.3743 - accuracy: 0.6161\n",
      "Epoch 64/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.3670 - accuracy: 0.6038WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3667 - accuracy: 0.6032\n",
      "Epoch 65/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.3465 - accuracy: 0.6099WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3502 - accuracy: 0.6094\n",
      "Epoch 66/100\n",
      "56/61 [==========================>...] - ETA: 0s - loss: 1.3528 - accuracy: 0.6177WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.3591 - accuracy: 0.6161\n",
      "Epoch 67/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.3108 - accuracy: 0.6293WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 1.3336 - accuracy: 0.6228\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.3014 - accuracy: 0.6295 ETA: 0s - loss: 1.3018 - accuracy: 0.WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3014 - accuracy: 0.6295\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.3151 - accuracy: 0.6233WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.3151 - accuracy: 0.6233\n",
      "Epoch 70/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.3068 - accuracy: 0.6207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.3081 - accuracy: 0.6187\n",
      "Epoch 71/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.2915 - accuracy: 0.6361WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.2939 - accuracy: 0.6352\n",
      "Epoch 72/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.2833 - accuracy: 0.6328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.2888 - accuracy: 0.6305\n",
      "Epoch 73/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.2781 - accuracy: 0.6339WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.2816 - accuracy: 0.6321\n",
      "Epoch 74/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.2925 - accuracy: 0.6261WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.2865 - accuracy: 0.6280\n",
      "Epoch 75/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.2787 - accuracy: 0.6250WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 1.2817 - accuracy: 0.6238\n",
      "Epoch 76/100\n",
      "57/61 [===========================>..] - ETA: 0s - loss: 1.2446 - accuracy: 0.6245WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 1.2341 - accuracy: 0.6259\n",
      "Epoch 77/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.2467 - accuracy: 0.6325WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 1.2480 - accuracy: 0.6347\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.2404 - accuracy: 0.6404WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.2404 - accuracy: 0.6404\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/61 [============================>.] - ETA: 0s - loss: 1.2453 - accuracy: 0.6448WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.2441 - accuracy: 0.6460\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.2271 - accuracy: 0.6465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.2271 - accuracy: 0.6465\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.2173 - accuracy: 0.6311WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.2173 - accuracy: 0.6311\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.1882 - accuracy: 0.6512WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1882 - accuracy: 0.6512\n",
      "Epoch 83/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.1849 - accuracy: 0.6510WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1783 - accuracy: 0.6512\n",
      "Epoch 84/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.1854 - accuracy: 0.6474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1849 - accuracy: 0.6481\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.6491WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1789 - accuracy: 0.6491\n",
      "Epoch 86/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.1718 - accuracy: 0.6594WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1701 - accuracy: 0.6589\n",
      "Epoch 87/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.1513 - accuracy: 0.6520WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1499 - accuracy: 0.6538\n",
      "Epoch 88/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.1631 - accuracy: 0.6509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1651 - accuracy: 0.6512\n",
      "Epoch 89/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.1546 - accuracy: 0.6449WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1528 - accuracy: 0.6460\n",
      "Epoch 90/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.1566 - accuracy: 0.6573WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.1681 - accuracy: 0.6543\n",
      "Epoch 91/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.1209 - accuracy: 0.6687WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1261 - accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.1103 - accuracy: 0.6641WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1103 - accuracy: 0.6641\n",
      "Epoch 93/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.1050 - accuracy: 0.6751WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.1158 - accuracy: 0.6718\n",
      "Epoch 94/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.0777 - accuracy: 0.6817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0776 - accuracy: 0.6821\n",
      "Epoch 95/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.0834 - accuracy: 0.6638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0860 - accuracy: 0.6651\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.0759 - accuracy: 0.6739WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0759 - accuracy: 0.6739\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.6636WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0881 - accuracy: 0.6636\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.0623 - accuracy: 0.6816WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0623 - accuracy: 0.6816\n",
      "Epoch 99/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.0618 - accuracy: 0.6790WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0602 - accuracy: 0.6791\n",
      "Epoch 100/100\n",
      "58/61 [===========================>..] - ETA: 0s - loss: 1.0631 - accuracy: 0.6805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 1.0650 - accuracy: 0.6796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9bea45700>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, label_array, epochs=100, callbacks=callbacks)\n",
    "# model.fit(features, label_array, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model,\n",
    "                    first_ingredient,\n",
    "                    idx_word,\n",
    "                    seed_length=4,\n",
    "                    new_words=50,\n",
    "                    diversity=1,\n",
    "                    return_output=False,\n",
    "                    n_gen=1):       # Number of generations?\n",
    "    \"\"\"Generate `new_words` words of output from a trained model and format into HTML.\"\"\"\n",
    "\n",
    "    # Identify code of the ingredient given by user:\n",
    "    for key, value in idx_word.items():\n",
    "        if value == first_ingredient:\n",
    "            first_ingr_code = key\n",
    "#     print(first_ingr_code)\n",
    "    \n",
    "    \n",
    "    # Identify index of ingredient given by user based on its code:    \n",
    "    a = []                              # List of all sequences where given ingredient appears (index of sequence + index of\n",
    "                                                                                                                  # ingredient)\n",
    "    for seq in sequences:\n",
    "        for word in seq:\n",
    "            if word == 10:\n",
    "                a.append((sequences.index(seq), seq.index(word)))\n",
    "    \n",
    "    b = random.choice(a)                # Randomly selected sequence (i.e. cocktail)\n",
    "    \n",
    "    len1 = len(sequences[b[0]])         # Lengh of randomly selected sequence where given ingredient is presented\n",
    "    len2 = b[1] + seed_length + 1       # Lengh of seed based on index of given ingredient in randomly selected \n",
    "\n",
    "    while len1 < len2:\n",
    "        b = random.choice(a)\n",
    "        len1 = len(sequences[b[0]])\n",
    "        len2 = b[1] + seed_length + 1\n",
    "\n",
    "    gen_list = []\n",
    "    \n",
    "    for n in range(n_gen):\n",
    "        # Extract the seed sequence\n",
    "        seed = sequences[b[0]][b[1]:(seed_length+1)]\n",
    "#         print(seed)\n",
    "        generated = seed          # Transform words to code for further decoding toghether with new added words\n",
    "#         print(generated)\n",
    "        \n",
    "        # Keep adding new words\n",
    "        for i in range(new_words):\n",
    "\n",
    "            # Make a prediction from the seed\n",
    "            preds = model.predict(np.array(seed).reshape(1, -1))[0].astype(np.float64)\n",
    "#             print(preds[0:10])\n",
    "            \n",
    "#             Diversify\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "#             print(preds)\n",
    "\n",
    "            # Softmax\n",
    "            preds = exp_preds / sum(exp_preds)\n",
    "#             print(preds[:10])\n",
    "\n",
    "            # Choose the next word\n",
    "            probas = np.random.multinomial(1, preds, 1)[0]\n",
    "#             print(probas)\n",
    "\n",
    "            next_idx = np.argmax(probas)\n",
    "#             print(next_idx)\n",
    "\n",
    "            # New seed adds on old word\n",
    "            seed += [next_idx]\n",
    "            generated.append(next_idx)\n",
    "#         print(generated)\n",
    "        \n",
    "#         Showing generated and actual abstract\n",
    "        n = []\n",
    "\n",
    "        for i in generated:\n",
    "            n.append(idx_word.get(i))\n",
    "\n",
    "        gen_list.append(n)\n",
    "    return(gen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_4_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_4_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-156-4a63bec1ce70>:53: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / diversity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Rum',\n",
       "  '60.0',\n",
       "  'ml',\n",
       "  'Cherry',\n",
       "  '1',\n",
       "  '1',\n",
       "  'slice',\n",
       "  'slice',\n",
       "  'garnish',\n",
       "  'garnish',\n",
       "  'Rum',\n",
       "  'Rum',\n",
       "  '14.0',\n",
       "  '14.0',\n",
       "  '1',\n",
       "  '1',\n",
       "  'twist',\n",
       "  'twist',\n",
       "  'garnish',\n",
       "  'garnish',\n",
       "  'Rum',\n",
       "  'Rum',\n",
       "  '45.0',\n",
       "  '45.0']]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_output(model, 'Rum', idx_word, new_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'ml',\n",
       " 2: '30.0',\n",
       " 3: '15.0',\n",
       " 4: 'Juice',\n",
       " 5: 'gr',\n",
       " 6: 'garnish',\n",
       " 7: '60.0',\n",
       " 8: '45.0',\n",
       " 9: 'Lemon',\n",
       " 10: 'Rum',\n",
       " 11: '1',\n",
       " 12: 'Vodka',\n",
       " 13: 'Gin',\n",
       " 14: 'Orange',\n",
       " 15: 'Sugar',\n",
       " 16: '22.5',\n",
       " 17: 'Cream',\n",
       " 18: 'Light',\n",
       " 19: '4.0',\n",
       " 20: '25.0',\n",
       " 21: 'Lime',\n",
       " 22: 'Brandy',\n",
       " 23: '1.0',\n",
       " 24: 'Liqueur',\n",
       " 25: 'Vermouth',\n",
       " 26: 'Cherry',\n",
       " 27: '10.0',\n",
       " 28: 'Triple',\n",
       " 29: 'Sec',\n",
       " 30: 'Amaretto',\n",
       " 31: '2.0',\n",
       " 32: '90.0',\n",
       " 33: 'berry',\n",
       " 34: 'Bitters',\n",
       " 35: 'White',\n",
       " 36: 'Sweet',\n",
       " 37: '120.0',\n",
       " 38: 'Grenadine',\n",
       " 39: 'Creme',\n",
       " 40: 'De',\n",
       " 41: 'Peel',\n",
       " 42: 'slice',\n",
       " 43: 'Water',\n",
       " 44: 'Irish',\n",
       " 45: 'Powdered',\n",
       " 46: 'Tequila',\n",
       " 47: 'Kahlua',\n",
       " 48: 'twist',\n",
       " 49: 'Egg',\n",
       " 50: 'Pineapple',\n",
       " 51: 'Dry',\n",
       " 52: 'Soda',\n",
       " 53: 'Maraschino',\n",
       " 54: 'Cranberry',\n",
       " 55: '6.0',\n",
       " 56: '0',\n",
       " 57: 'top',\n",
       " 58: 'up',\n",
       " 59: \"Bailey'S\",\n",
       " 60: 'Schnapps',\n",
       " 61: 'Dark',\n",
       " 62: 'Sour',\n",
       " 63: '150.0',\n",
       " 64: '14.0',\n",
       " 65: 'Milk',\n",
       " 66: '20.0',\n",
       " 67: 'Syrup',\n",
       " 68: 'Absolut',\n",
       " 69: 'Peach',\n",
       " 70: 'Coffee',\n",
       " 71: '7.5',\n",
       " 72: '50.0',\n",
       " 73: '8.0',\n",
       " 74: 'Whiskey',\n",
       " 75: 'Bourbon',\n",
       " 76: 'Wine',\n",
       " 77: '75.0',\n",
       " 78: 'Ginger',\n",
       " 79: '40.0',\n",
       " 80: 'Scotch',\n",
       " 81: 'Superfine',\n",
       " 82: 'Cacao',\n",
       " 83: 'Vanilla',\n",
       " 84: '128.0',\n",
       " 85: 'And',\n",
       " 86: 'Curacao',\n",
       " 87: 'Nutmeg',\n",
       " 88: '0.5',\n",
       " 89: 'Red',\n",
       " 90: '5.0',\n",
       " 91: 'Raspberry',\n",
       " 92: '151',\n",
       " 93: 'Proof',\n",
       " 94: '12.5',\n",
       " 95: 'grated',\n",
       " 96: 'Apple',\n",
       " 97: 'Blue',\n",
       " 98: 'Club',\n",
       " 99: '750.0',\n",
       " 100: 'Grand',\n",
       " 101: 'Marnier',\n",
       " 102: 'Melon',\n",
       " 103: 'Ice-Cream',\n",
       " 104: '37.5',\n",
       " 105: 'Apricot',\n",
       " 106: '360.0',\n",
       " 107: 'Midori',\n",
       " 108: 'Malibu',\n",
       " 109: 'Beer',\n",
       " 110: 'Ale',\n",
       " 111: 'Salt',\n",
       " 112: 'Blended',\n",
       " 113: '180.0',\n",
       " 114: '236.5',\n",
       " 115: 'Sambuca',\n",
       " 116: 'Chambord',\n",
       " 117: 'Coca-Cola',\n",
       " 118: 'Citron',\n",
       " 119: 'Southern',\n",
       " 120: 'Comfort',\n",
       " 121: 'Menthe',\n",
       " 122: 'Chocolate',\n",
       " 123: 'Champagne',\n",
       " 124: 'Lemonade',\n",
       " 125: '2.5',\n",
       " 126: 'Benedictine',\n",
       " 127: '330.0',\n",
       " 128: 'Galliano',\n",
       " 129: 'Sauce',\n",
       " 130: 'Coconut',\n",
       " 131: 'Mint',\n",
       " 132: 'Mix',\n",
       " 133: 'Whipped',\n",
       " 134: '60',\n",
       " 135: 'Green',\n",
       " 136: 'Lager',\n",
       " 137: 'Cointreau',\n",
       " 138: 'Jägermeister',\n",
       " 139: 'Jack',\n",
       " 140: 'Strawberry',\n",
       " 141: 'Hot',\n",
       " 142: 'Cognac',\n",
       " 143: '3.0',\n",
       " 144: '946.0',\n",
       " 145: '240.0',\n",
       " 146: 'Cider',\n",
       " 147: '64.0',\n",
       " 148: 'Tea',\n",
       " 149: 'Frozen',\n",
       " 150: '125.0',\n",
       " 151: '32.0',\n",
       " 152: '270.0',\n",
       " 153: 'Goldschlager',\n",
       " 154: 'Daniels',\n",
       " 155: 'wedge',\n",
       " 156: 'Grapefruit',\n",
       " 157: 'Angostura',\n",
       " 158: 'Sprite',\n",
       " 159: 'Cassis',\n",
       " 160: 'Sherry',\n",
       " 161: 'Sloe',\n",
       " 162: 'Tabasco',\n",
       " 163: '0.36',\n",
       " 164: 'Port',\n",
       " 165: '100.0',\n",
       " 166: 'Olive',\n",
       " 167: '474.0',\n",
       " 168: 'Wild',\n",
       " 169: 'Turkey',\n",
       " 170: '7-Up',\n",
       " 171: 'Frangelico',\n",
       " 172: 'Strawberries',\n",
       " 173: 'Tonic',\n",
       " 174: 'leaf(ves)',\n",
       " 175: 'Heavy',\n",
       " 176: 'Fruit',\n",
       " 177: 'Campari',\n",
       " 178: 'whole',\n",
       " 179: 'Cinnamon',\n",
       " 180: 'Grape',\n",
       " 181: 'Jamaican',\n",
       " 182: 'Crown',\n",
       " 183: 'Royal',\n",
       " 184: 'Banana',\n",
       " 185: 'Everclear',\n",
       " 186: 'Kool-Aid',\n",
       " 187: 'around',\n",
       " 188: 'the',\n",
       " 189: 'rim',\n",
       " 190: '1/2',\n",
       " 191: 'Extract',\n",
       " 192: '11.25',\n",
       " 193: 'Lemon-Lime',\n",
       " 194: 'Or',\n",
       " 195: '105.0',\n",
       " 196: 'Kurant',\n",
       " 197: 'Banane',\n",
       " 198: '44.0',\n",
       " 199: '6.25',\n",
       " 200: 'Fresh',\n",
       " 201: 'Chartreuse',\n",
       " 202: 'Blackberry',\n",
       " 203: 'Cloves',\n",
       " 204: '3',\n",
       " 205: 'Mountain',\n",
       " 206: 'Dew',\n",
       " 207: 'Of',\n",
       " 208: '473.0',\n",
       " 209: '8.333333333333332',\n",
       " 210: '3785.0',\n",
       " 211: 'Guinness',\n",
       " 212: 'Stout',\n",
       " 213: 'Root',\n",
       " 214: 'Surge',\n",
       " 215: '175.0',\n",
       " 216: 'Godiva',\n",
       " 217: 'Butterscotch',\n",
       " 218: 'Tomato',\n",
       " 219: '711.0',\n",
       " 220: 'Corona',\n",
       " 221: 'Bacardi',\n",
       " 222: 'Limon',\n",
       " 223: 'Cachaca',\n",
       " 224: 'Yolk',\n",
       " 225: 'Spiced',\n",
       " 226: '42.0',\n",
       " 227: '1000.0',\n",
       " 228: 'Anis',\n",
       " 229: '12.0',\n",
       " 230: 'Jim',\n",
       " 231: 'Beam',\n",
       " 232: 'Añejo',\n",
       " 233: 'Applejack',\n",
       " 234: '3.125',\n",
       " 235: '18.75',\n",
       " 236: 'Nectar',\n",
       " 237: 'Pisang',\n",
       " 238: 'Ambon',\n",
       " 239: '0.72',\n",
       " 240: 'Yellow',\n",
       " 241: '6',\n",
       " 242: '1892.5',\n",
       " 243: 'Iced',\n",
       " 244: 'Cordial',\n",
       " 245: 'Smirnoff',\n",
       " 246: '210.0',\n",
       " 247: 'Prosecco',\n",
       " 248: 'Tropical',\n",
       " 249: 'Tia',\n",
       " 250: 'Maria',\n",
       " 251: '2000.0',\n",
       " 252: 'Advocaat',\n",
       " 253: 'Grated',\n",
       " 254: 'Peachtree',\n",
       " 255: '300.0',\n",
       " 256: '28.0',\n",
       " 257: 'Damn',\n",
       " 258: '2',\n",
       " 259: 'Blackcurrant',\n",
       " 260: '70.0',\n",
       " 261: 'Punch',\n",
       " 262: 'Pisco',\n",
       " 263: 'Pepper',\n",
       " 264: 'Skimmed',\n",
       " 265: 'Agave',\n",
       " 266: '80.0',\n",
       " 267: 'Cold',\n",
       " 268: 'Schweppes',\n",
       " 269: 'Drambuie',\n",
       " 270: 'Orgeat',\n",
       " 271: 'Pepsi',\n",
       " 272: 'Cola',\n",
       " 273: '1750.0',\n",
       " 274: 'Rub',\n",
       " 275: '355.0',\n",
       " 276: 'Anisette',\n",
       " 277: 'Ouzo',\n",
       " 278: 'Zima',\n",
       " 279: '480.0',\n",
       " 280: 'Rumple',\n",
       " 281: 'Minze',\n",
       " 282: 'Johnnie',\n",
       " 283: 'Walker',\n",
       " 284: '200.0',\n",
       " 285: 'Kirschwasser',\n",
       " 286: '43.75',\n",
       " 287: '165.0',\n",
       " 288: 'Kummel',\n",
       " 289: '22.0',\n",
       " 290: '3784.0',\n",
       " 291: 'Brown',\n",
       " 292: 'Allspice',\n",
       " 293: 'Ground',\n",
       " 294: 'sticks',\n",
       " 295: '600.0',\n",
       " 296: '4000.0',\n",
       " 297: 'Candy',\n",
       " 298: 'jelly',\n",
       " 299: 'fish',\n",
       " 300: '(candy)',\n",
       " 301: 'Maui',\n",
       " 302: 'Gold',\n",
       " 303: 'Rye',\n",
       " 304: 'Passion',\n",
       " 305: '52.5',\n",
       " 306: \"Boone's\",\n",
       " 307: 'Hill',\n",
       " 308: 'Berry',\n",
       " 309: 'Celery',\n",
       " 310: 'Worcestershire',\n",
       " 311: 'Caramel',\n",
       " 312: 'Mini-Snickers',\n",
       " 313: 'Bars',\n",
       " 314: '450.0',\n",
       " 315: 'Label',\n",
       " 316: 'Erin',\n",
       " 317: 'Mure',\n",
       " 318: 'Muscatel',\n",
       " 319: 'Demerara',\n",
       " 320: 'Heering',\n",
       " 321: 'Brine',\n",
       " 322: 'Dubonnet',\n",
       " 323: 'Rouge',\n",
       " 324: 'St.',\n",
       " 325: 'Germain',\n",
       " 326: 'pinch',\n",
       " 327: 'Lavender',\n",
       " 328: 'sprigs',\n",
       " 329: 'Whipping',\n",
       " 330: 'Condensed',\n",
       " 331: '390.0',\n",
       " 332: '177.75',\n",
       " 333: 'Firewater',\n",
       " 334: 'Peppar',\n",
       " 335: 'Dr.',\n",
       " 336: '87.5',\n",
       " 337: 'Sarsaparilla',\n",
       " 338: '262.5',\n",
       " 339: '62.5',\n",
       " 340: 'Sirup',\n",
       " 341: 'Roses',\n",
       " 342: 'Carbonated',\n",
       " 343: '4',\n",
       " 344: 'Hard',\n",
       " 345: 'Whisky',\n",
       " 346: 'Very',\n",
       " 347: 'strip',\n",
       " 348: 'Aperol',\n",
       " 349: 'Tennessee',\n",
       " 350: 'Baileys',\n",
       " 351: '58.33333333333333',\n",
       " 352: 'Jello',\n",
       " 353: '88.0',\n",
       " 354: 'Grain',\n",
       " 355: 'Alcohol',\n",
       " 356: 'Apfelkorn',\n",
       " 357: 'Russchian',\n",
       " 358: 'Kiwi',\n",
       " 359: 'Bitter',\n",
       " 360: 'Turkish',\n",
       " 361: '237.0',\n",
       " 362: 'Tropicana',\n",
       " 363: '49.99999999999999',\n",
       " 364: 'Hazlenut',\n",
       " 365: 'Double',\n",
       " 366: 'Cocoa',\n",
       " 367: 'Powder',\n",
       " 368: 'Absinthe',\n",
       " 369: '12',\n",
       " 370: 'Sweetened',\n",
       " 371: 'Oreo',\n",
       " 372: 'Cookie',\n",
       " 373: 'Pink',\n",
       " 374: 'Black',\n",
       " 375: '250.0',\n",
       " 376: '1500.0',\n",
       " 377: '225.0',\n",
       " 378: 'Plain',\n",
       " 379: 'Ricard',\n",
       " 380: 'Peychaud',\n",
       " 381: '990.0',\n",
       " 382: '192.0',\n",
       " 383: 'Squash',\n",
       " 384: 'Cherries',\n",
       " 385: '1380.0',\n",
       " 386: '840.0',\n",
       " 387: 'Berries',\n",
       " 388: 'Aquavit',\n",
       " 389: 'Yukon',\n",
       " 390: 'Maple',\n",
       " 391: 'Lillet',\n",
       " 392: 'Blanc',\n",
       " 393: 'Unsweetened',\n",
       " 394: 'Half-And-Half',\n",
       " 395: 'Limeade',\n",
       " 396: '160.0'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions below have been copied from https://github.com/WillKoehrsen/recurrent-neural-networks/blob/master/notebooks/Exploring%20Model%20Results.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model,\n",
    "                    sequences,\n",
    "                    idx_word,\n",
    "                    seed_length=50,\n",
    "                    new_words=50,\n",
    "                    diversity=1,\n",
    "                    return_output=False,\n",
    "                    n_gen=1):\n",
    "    \"\"\"Generate `new_words` words of output from a trained model and format into HTML.\"\"\"\n",
    "\n",
    "    # Choose a random sequence\n",
    "    seq = random.choice(sequences)\n",
    "#     print(seq)\n",
    "    # Choose a random starting point\n",
    "#     seed_idx = random.randint(0, len(seq) - seed_length - 10)\n",
    "    seed_idx = random.randint(0, len(seq))\n",
    "#     print(seed_idx)\n",
    "    # Ending index for seed\n",
    "    end_idx = seed_idx + seed_length\n",
    "#     print(end_idx)\n",
    "    gen_list = []\n",
    "\n",
    "    for n in range(n_gen):\n",
    "        # Extract the seed sequence\n",
    "        seed = seq[seed_idx:end_idx]\n",
    "#         print(seed)\n",
    "        original_sequence = [idx_word[i] for i in seed]\n",
    "#         print(original_sequence)\n",
    "        generated = seed[:] + ['#']\n",
    "#         print(generated)\n",
    "\n",
    "        # Find the actual entire sequence\n",
    "        actual = generated[:] + seq[end_idx:end_idx + new_words]\n",
    "#         print(actual)\n",
    "        # Keep adding new words\n",
    "        for i in range(new_words):\n",
    "            print(i)\n",
    "\n",
    "            # Make a prediction from the seed\n",
    "            preds1 = model.predict(np.array(seed).reshape(1, -1))[0].astype(np.float64)\n",
    "#             print(preds1)\n",
    "\n",
    "            # Diversify\n",
    "            preds = np.log(preds1) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            print(type(exp_preds[:1]))\n",
    "\n",
    "            # Softmax\n",
    "            preds = exp_preds / sum(exp_preds)\n",
    "            print(preds1 == preds)\n",
    "\n",
    "            # Choose the next word\n",
    "            probas = np.random.multinomial(1, preds, 1)[0]\n",
    "#             print(probas)\n",
    "\n",
    "            next_idx = np.argmax(probas)\n",
    "#             print(next_idx)\n",
    "\n",
    "            # New seed adds on old word\n",
    "            #             seed = seed[1:] + [next_idx]\n",
    "            seed += [next_idx]\n",
    "            generated.append(next_idx)\n",
    "        print(generated)\n",
    "\n",
    "        # Showing generated and actual abstract\n",
    "        n = []\n",
    "\n",
    "        for i in generated:\n",
    "#             n.append(idx_word.get(i, '< --- >'))\n",
    "            n.append(idx_word.get(i))\n",
    "\n",
    "        gen_list.append(n)\n",
    "    return(gen_list)\n",
    "\n",
    "#     a = []\n",
    "\n",
    "#     for i in actual:\n",
    "#         a.append(idx_word.get(i, '< --- >'))\n",
    "\n",
    "#     a = a[seed_length:]\n",
    "\n",
    "#     gen_list = [gen[seed_length:seed_length + len(a)] for gen in gen_list]\n",
    "\n",
    "#     if return_output:\n",
    "#         return original_sequence, gen_list, a\n",
    "\n",
    "#     # HTML formatting\n",
    "#     seed_html = ''\n",
    "#     seed_html = addContent(seed_html, header(\n",
    "#         'Seed Sequence', color='darkblue'))\n",
    "#     seed_html = addContent(seed_html,\n",
    "#                            box(remove_spaces(' '.join(original_sequence))))\n",
    "\n",
    "#     gen_html = ''\n",
    "#     gen_html = addContent(gen_html, header('RNN Generated', color='darkred'))\n",
    "#     gen_html = addContent(gen_html, box(remove_spaces(' '.join(gen_list[0]))))\n",
    "\n",
    "#     a_html = ''\n",
    "#     a_html = addContent(a_html, header('Actual', color='darkgreen'))\n",
    "#     a_html = addContent(a_html, box(remove_spaces(' '.join(a))))\n",
    "\n",
    "#     return seed_html, gen_html, a_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "2\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "3\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "4\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "6\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "7\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "8\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "9\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "[7, 1, 70, 24, 2, '#', 1, 210, 5, 13, 5, 51, 14, 42, 6, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['60.0',\n",
       "  'ml',\n",
       "  'Coffee',\n",
       "  'Liqueur',\n",
       "  '30.0',\n",
       "  None,\n",
       "  'ml',\n",
       "  '3785.0',\n",
       "  'gr',\n",
       "  'Gin',\n",
       "  'gr',\n",
       "  'Dry',\n",
       "  'Orange',\n",
       "  'slice',\n",
       "  'garnish',\n",
       "  'garnish']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_output(model, sequences, idx_word, seed_length=5, new_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addContent(old_html, raw_html):\n",
    "    old_html += raw_html\n",
    "    return old_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(text, color = 'black', gen_text = None):\n",
    "    if gen_text:\n",
    "        raw_html = f'<h1 style=\"color: {color};\"><p><center>' + str(\n",
    "        text) + '<span style=\"color: red\">' + str(gen_text) + '</center></p></h1>'\n",
    "    else:\n",
    "        raw_html = f'<h1 style=\"color: {color};\"><center>' + str(\n",
    "            text) + '</center></h1>'\n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box(text, gen_text=None):\n",
    "    if gen_text:\n",
    "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>' + str(\n",
    "            text) +'<span style=\"color: red\">' + str(gen_text) + '</p></div>'\n",
    "\n",
    "    else:\n",
    "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\">' + str(\n",
    "            text) + '</div>'\n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_sequence(model, s, word_idx, idx_word, \n",
    "                  diversity = 0.75, num_words = 50):\n",
    "    \"\"\"Generate output starting from a seed sequence.\"\"\"\n",
    "    # Original formated text\n",
    "    start = format_sequence(s).split()\n",
    "    gen = []\n",
    "    s = start[:]\n",
    "    # Generate output\n",
    "    for _ in range(num_words):\n",
    "        # Conver to arry\n",
    "        x = np.array([word_idx.get(word, 0) for word in s]).reshape((1, -1))\n",
    "\n",
    "        # Make predictions\n",
    "        preds = model.predict(x)[0].astype(float)\n",
    "\n",
    "        # Diversify\n",
    "        preds = np.log(preds) / diversity\n",
    "        exp_preds = np.exp(preds)\n",
    "        # Softmax\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        # Pick next index\n",
    "        next_idx = np.argmax(np.random.multinomial(1, preds, size = 1))\n",
    "        s.append(idx_word[next_idx])\n",
    "        gen.append(idx_word[next_idx])\n",
    "    \n",
    "    # Formatting in html\n",
    "    start = remove_spaces(' '.join(start)) + ' '\n",
    "    gen = remove_spaces(' '.join(gen)) \n",
    "    html = ''\n",
    "    html = addContent(html, header('Input Seed ', color = 'black', gen_text = 'Network Output'))\n",
    "    html = addContent(html, box(start, gen))\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(s):\n",
    "    \"\"\"Remove spaces around punctuation\"\"\"\n",
    "    s = re.sub(r'\\s+([.,;?])', r'\\1', s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_html, gen_html, a_html = generate_output(model, sequences, idx_word)\n",
    "HTML(seed_html)\n",
    "HTML(gen_html)\n",
    "HTML(a_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
